{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b44686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in path to GIS folder, eg C:\\Dropbox\\..\\AIS_Barcin_Hoyuk\\AIS\\GIS\\: G:\\\\Barcin_Project\\\\GIS\\\\\n",
      "Fill in path where to create OUTPUT folder:, eg C:\\Dropbox\\..\\AIS_Barcin_Hoyuk_DB_GIS\\: G:\\\\Barcin_Project\\\\\n"
     ]
    }
   ],
   "source": [
    "#Created by Maurice de Kleijn for the datamanagement of the the archaeological project Barin Hoyuk 16042024\n",
    "#The purpose of this script is to merge all the shapefiles of the individual plans into one so it can be queried more easily in QGIS. This script only uses Free and Open Sources python libraries \n",
    "\n",
    "#Import the required libraries\n",
    "import shutil \n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "#Step 1 Define the variables for the locations of the GIS files\n",
    "org_GIS = input(\"Fill in path to GIS folder, eg C:\\Dropbox\\..\\AIS_Barcin_Hoyuk\\AIS\\GIS\\: \")\n",
    "loc_output = input(\"Fill in path where to create OUTPUT folder:, eg C:\\Dropbox\\..\\AIS_Barcin_Hoyuk_DB_GIS\\: \")\n",
    "#Create the output folder\n",
    "os.system('md ' + loc_output + 'OUTPUT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 add the filename of the original shapefile as a collumn so it is always clear where an object came from.\n",
    "#Create a list of all the shapefiles in the folder\n",
    "file_pattern = '**/*.shp'\n",
    "file_list = glob.glob(os.path.join(org_GIS, file_pattern), recursive=True)\n",
    "#Remove the TEMP layer from the list\n",
    "file_list = [f for f in file_list if '_TEMP' not in os.path.basename(f)]\n",
    "#Remove all the template files from the list\n",
    "file_list = [item for item in file_list if \"RENAME\" not in item]\n",
    "\n",
    "#Read the list and add the shapefile name\n",
    "for file in file_list:\n",
    "    # Open the shapefile with Geopandas\n",
    "    gdf = gpd.read_file(file)\n",
    "    # Get the filename of the shapefile without the extension\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "    # Add a new column to the attribute table and populate it with the filename\n",
    "    gdf['shpname'] = (filename)\n",
    "    index_cols = [col for col in gdf.columns if 'index' in col]\n",
    "    if index_cols:\n",
    "        gdf = gdf.drop(index_cols, axis=1)\n",
    "    level_0_cols = [col for col in gdf.columns if 'level_0' in col]\n",
    "    if level_0_cols:\n",
    "        gdf = gdf.drop(level_0_cols, axis=1)\n",
    "    # Save the modified shapefile\n",
    "    gdf.to_file(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9f3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 create the Locus layer\n",
    "#Put all the locus files from the various folders in a list \n",
    "file_pattern = '**/*_locus.shp'\n",
    "file_list = glob.glob(os.path.join(org_GIS, file_pattern), recursive=True)\n",
    "\n",
    "#Remove the TEMP locus layer from the list\n",
    "file_list = [f for f in file_list if '_TEMP' not in os.path.basename(f)]\n",
    "#Remove all the template files from the list\n",
    "file_list = [item for item in file_list if \"RENAME\" not in item]\n",
    "\n",
    "#Merge all the locus files from the list\n",
    "#Read in each shapefile as a GeoDataFrame\n",
    "gdfs = [gpd.read_file(shapefile) for shapefile in file_list]\n",
    "\n",
    "#Concatenate the GeoDataFrames into one\n",
    "merged_gdf = pd.concat(gdfs, ignore_index=True)\n",
    "\n",
    "#Convert back to a GeoDataFrame\n",
    "merged_gdf = gpd.GeoDataFrame(merged_gdf, crs=gdfs[0].crs, geometry='geometry')\n",
    "\n",
    "#Save the merged shapefile\n",
    "merged_gdf.to_file(loc_output+'OUTPUT\\\\BH_locus.shp')\n",
    "shp_output = loc_output+'OUTPUT\\\\BH_locus.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ca955cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 Create the joinfld in the newly created locus file\n",
    "#Read in the shapefile as a geopandas GeoDataFrame\n",
    "gdf = gpd.read_file(shp_output)\n",
    "\n",
    "col1 = 'Trench'\n",
    "col2 = 'Locus'\n",
    "\n",
    "# Add the new field to the GeoDataFrame\n",
    "gdf['joinfld'] = gdf.apply(lambda row: row[col1] + '_' + str(int(row[col2])), axis=1)\n",
    "\n",
    "#Drop collumns\n",
    "gdf = gdf.drop(['index'], axis=1)\n",
    "\n",
    "# Write the updated GeoDataFrame to a new shapefile\n",
    "gdf.to_file(shp_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "459fc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 Create centroid point with labels of locus\n",
    "# Define the paths to locus polygon shp polygon and the point shapefile to be created\n",
    "poly_path = loc_output+'OUTPUT\\\\BH_locus.shp'\n",
    "point_path = loc_output+'OUTPUT\\\\BH_locus_points.shp'\n",
    "\n",
    "# Open the polygon shapefile with Geopandas\n",
    "poly_gdf = gpd.read_file(poly_path)\n",
    "\n",
    "# Calculate the centroid of each polygon\n",
    "centroids = poly_gdf['geometry'].centroid\n",
    "\n",
    "# Create a new Geopandas GeoDataFrame with the centroids as points\n",
    "point_gdf = gpd.GeoDataFrame(poly_gdf.drop('geometry', axis=1), crs=poly_gdf.crs, geometry=centroids)\n",
    "\n",
    "# Save the new point shapefile\n",
    "point_gdf.to_file(point_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f21e6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "heights\n",
      "height_differences\n",
      "graphic\n",
      "finds_samples\n",
      "unclear_limits\n",
      "underlying_level_lines\n",
      "underlying_level_lines\n"
     ]
    }
   ],
   "source": [
    "#Step 6 Create merged layers for all other files\n",
    "type_list = ['annotation','heights','height_differences','graphic','finds_samples','unclear_limits','underlying_level_lines','underlying_level_lines']\n",
    "\n",
    "for item in type_list:\n",
    "    file_pattern = '**/*_'+item+'.shp'\n",
    "    file_list2 = glob.glob(os.path.join(org_GIS, file_pattern), recursive=True)\n",
    "    file_list2 = [item for item in file_list2 if \"RENAME\" not in item]\n",
    "    # read in each shapefile as a GeoDataFrame    \n",
    "    gdfs = [gpd.read_file(shapefile).to_crs('EPSG:2320') for shapefile in file_list2]\n",
    "    merged_gdf = pd.concat(gdfs, ignore_index=True)\n",
    "    merged_gdf = gpd.GeoDataFrame(merged_gdf, crs=gdfs[0].crs, geometry='geometry')\n",
    "    merged_gdf.to_file(loc_output+'OUTPUT\\\\BH_'+item+'.shp')\n",
    "    file_list2 =[]\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6928ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
